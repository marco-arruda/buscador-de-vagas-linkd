# Buscador de Vagas LinkedIn

Um projeto bÃ¡sico de web scraping para buscar vagas de emprego no LinkedIn, focado na regiÃ£o de Recife, Pernambuco, Brasil.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa um web scraper que busca vagas de emprego na versÃ£o pÃºblica do LinkedIn (sem necessidade de login). O scraper coleta informaÃ§Ãµes como tÃ­tulo da vaga, empresa, localizaÃ§Ã£o e link para a vaga.

## ğŸš€ Funcionalidades

- Busca vagas no LinkedIn sem necessidade de autenticaÃ§Ã£o
- Filtra por palavras-chave e localizaÃ§Ã£o
- Extrai informaÃ§Ãµes das vagas:
  - TÃ­tulo da vaga
  - Nome da empresa
  - LocalizaÃ§Ã£o
  - Link para a vaga
  - Data de postagem (quando disponÃ­vel)
- Exibe resultados no console de forma formatada
- Exporta resultados para arquivo CSV

## ğŸ“¦ Requisitos

- Python 3.7 ou superior
- DependÃªncias listadas em `requirements.txt`:
  - requests
  - beautifulsoup4
  - lxml

## ğŸ”§ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/marco-arruda/buscador-de-vagas-linkd.git
cd buscador-de-vagas-linkd
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸ’» Como Usar

### Uso BÃ¡sico

Execute o script principal para buscar todas as vagas em Recife:

```bash
python buscador_vagas.py
```

### PersonalizaÃ§Ã£o

VocÃª pode personalizar a busca editando o arquivo `buscador_vagas.py` na funÃ§Ã£o `main()`:

```python
# Buscar vagas com palavras-chave especÃ­ficas
vagas = scraper.buscar_vagas(
    keywords="Python Desenvolvedor",  # Palavras-chave
    location="Recife, Pernambuco, Brasil",  # LocalizaÃ§Ã£o
    num_paginas=2  # NÃºmero de pÃ¡ginas para buscar
)
```

### Uso ProgramÃ¡tico

VocÃª tambÃ©m pode usar a classe `LinkedInJobScraper` em seus prÃ³prios scripts:

```python
from buscador_vagas import LinkedInJobScraper

# Criar instÃ¢ncia do scraper
scraper = LinkedInJobScraper()

# Buscar vagas
vagas = scraper.buscar_vagas(
    keywords="desenvolvedor",
    location="Recife, Pernambuco, Brasil",
    num_paginas=1
)

# Exibir vagas
scraper.exibir_vagas(vagas)

# Salvar em CSV
scraper.salvar_csv(vagas, "minhas_vagas.csv")
```

## ğŸ“Š Formato de SaÃ­da

### Console
As vagas sÃ£o exibidas no console com o seguinte formato:
```
1. TÃ­tulo da Vaga
   Empresa: Nome da Empresa
   LocalizaÃ§Ã£o: Cidade, Estado
   Data: Data de postagem
   Link: URL da vaga
```

### CSV
Um arquivo CSV Ã© gerado automaticamente com as colunas:
- titulo
- empresa
- localizacao
- link
- data_postagem

Nome do arquivo: `vagas_linkedin_YYYYMMDD_HHMMSS.csv`

## âš ï¸ ObservaÃ§Ãµes Importantes

1. **Respeite os Termos de Uso**: Este scraper foi desenvolvido para uso educacional. Sempre respeite os termos de serviÃ§o do LinkedIn.

2. **Rate Limiting**: O script inclui pausas entre requisiÃ§Ãµes para nÃ£o sobrecarregar o servidor.

3. **MudanÃ§as no HTML**: O LinkedIn pode alterar a estrutura HTML de suas pÃ¡ginas. Se o scraper parar de funcionar, pode ser necessÃ¡rio atualizar os seletores CSS.

4. **LimitaÃ§Ãµes**: 
   - Funciona apenas com a versÃ£o pÃºblica do LinkedIn (nÃ£o requer login)
   - Limitado Ã s informaÃ§Ãµes visÃ­veis na pÃ¡gina de busca
   - Pode nÃ£o capturar todas as vagas disponÃ­veis

## ğŸ› ï¸ Estrutura do Projeto

```
buscador-de-vagas-linkd/
â”‚
â”œâ”€â”€ buscador_vagas.py      # Script principal
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â”œâ”€â”€ .gitignore            # Arquivos a serem ignorados pelo Git
â””â”€â”€ README.md             # DocumentaÃ§Ã£o
```

## ğŸ“ Exemplo de Uso

```bash
$ python buscador_vagas.py

============================================================
BUSCADOR DE VAGAS LINKEDIN
============================================================

1. Buscando todas as vagas em Recife...
Buscando vagas para: todas as categorias
LocalizaÃ§Ã£o: Recife, Pernambuco, Brasil
------------------------------------------------------------

Buscando pÃ¡gina 1...
Encontradas 25 vagas na pÃ¡gina 1

============================================================
VAGAS ENCONTRADAS: 25
============================================================

1. Desenvolvedor Python
   Empresa: Empresa XYZ
   LocalizaÃ§Ã£o: Recife, PE
   Data: 2025-01-05
   Link: https://www.linkedin.com/jobs/view/...
------------------------------------------------------------
...

âœ“ 25 vagas salvas em: vagas_linkedin_20250107_151230.csv
```

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir melhorias
- Enviar pull requests

## ğŸ“„ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto e estÃ¡ disponÃ­vel para uso educacional.

## ğŸ‘¤ Autor

Marco Arruda

## ğŸ”— Links Ãšteis

- [LinkedIn Jobs](https://www.linkedin.com/jobs/)
- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Requests Documentation](https://requests.readthedocs.io/)

## ğŸš€ API

Este repositÃ³rio inclui uma API simples usando FastAPI em `api/search.py`.

Endpoint principal (local):

- POST /  (quando o servidor estiver rodando em http://localhost:8000/)

Payload (JSON):

```json
{
   "query": "Desenvolvedor Python",
   "location": "Recife, Pernambuco, Brasil",
   "num_pages": 1
}
```

Resposta: lista de objetos com os campos `titulo`, `empresa`, `localizacao`, `link`, `data_postagem`.

Teste local com uvicorn:

```bash
pip install -r requirements.txt
uvicorn api.search:app --reload --port 8000
```

Em seguida, faÃ§a uma requisiÃ§Ã£o POST para `http://localhost:8000/` com o JSON do payload acima.

Cache
-----

Esta API possui um cache em memÃ³ria (LRU) com TTL para evitar chamadas repetidas ao LinkedIn
durante curtos intervalos. ConfiguraÃ§Ãµes padrÃ£o (em `api/search.py`):

- TTL: 300 segundos (5 minutos)
- MÃ¡ximo de entradas: 128 (eviction LRU automÃ¡tica)

O endpoint adiciona um header `X-Cache` na resposta com valor `HIT` quando o resultado veio do cache,
ou `MISS` quando foi buscado novamente.
